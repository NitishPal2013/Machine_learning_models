{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Text to text generation using RNN model\n",
        "\n",
        "This model takes a txt file and tokenize it on character basis. These tokens get feed to our RNN model which make our model context aware. This will help use to generate text when a prompt is given to it."
      ],
      "metadata": {
        "id": "9LA84RrfVNYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWYlmC50FZmv",
        "outputId": "daefacb1-9931-4385-936d-92e48e524190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5uHJfPsuFgbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n"
      ],
      "metadata": {
        "id": "GDy93L6VFwl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below text file contains a shakespeare play on which I am gonna work."
      ],
      "metadata": {
        "id": "4Bur5VkqIr7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "JtlWdRNJGdiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding = 'utf-8')"
      ],
      "metadata": {
        "id": "KdZhCCXAG0UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xXimu7RITTi",
        "outputId": "d37a4cea-177a-4a01-bd6c-35694d65395f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4NgFJEefIjD6",
        "outputId": "8d827e59-316a-4aca-ef5b-ce54b2bae407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of characters in out play is 1115394."
      ],
      "metadata": {
        "id": "_k8Y1MRpI3h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))"
      ],
      "metadata": {
        "id": "VQBVSdvWIkzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# length og out vocabulary\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrowX31dJAIM",
        "outputId": "e3b722ed-9d5c-46fa-8792-3d396c035c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the mapping which converts each chraracter into an interger ans specifically positive number.\n",
        "char_to_idx = {u:i for i,u in enumerate(vocab)}\n",
        "char_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GNl-UAlJBhS",
        "outputId": "772e5aa8-179f-4eca-e449-26e937e5378f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping of index to char is simply a np.array like this\n",
        "idx_to_char = np.array(vocab)\n",
        "idx_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2DA4IgaJg_y",
        "outputId": "32bdf8ef-6b23-4aa3-d457-3488e3e4a14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
              "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
              "      dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(sentence):\n",
        "  return np.array([char_to_idx[ch] for ch in sentence])\n",
        "\n",
        "def decoder(arr):\n",
        "  try:\n",
        "    arr = arr.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx_to_char[arr])"
      ],
      "metadata": {
        "id": "HJaIAOwJJ8VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder(\"Oh Juliet!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr-E6yYnKAzR",
        "outputId": "108e86fa-2115-45b9-aa9f-be6b4e12ae5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27, 46,  1, 22, 59, 50, 47, 43, 58,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder([27, 46,  1, 22, 59, 50, 47, 43, 58,  2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_mrjCivtLZmy",
        "outputId": "163e68d3-bfe0-41a6-f806-a986a5c48590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Oh Juliet!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training examples would be the shift of our text by one character from the input to the output.\n",
        "\n",
        "input example are bounder by vertical bars : |fdslakfjdsl|k jfasdlk fj;adslkjf ....\n",
        "ouput example are bounder by vertical bars : f|dslakfjdslk| jfasdlk fj;adslkjf ....\n",
        "input: fdslakfjdsl then output: dslakfjdslk\n"
      ],
      "metadata": {
        "id": "dVPCFz8YLmyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 200 # length of input sequence\n",
        "examples_per_epoch = len(text) // (seq_length + 1)"
      ],
      "metadata": {
        "id": "_sBXRBaTLdGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = encoder(text)"
      ],
      "metadata": {
        "id": "QgHki2lEe1f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "metadata": {
        "id": "20tCx1PfcD4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = char_dataset.batch(seq_length + 1, drop_remainder = True )"
      ],
      "metadata": {
        "id": "5SrDU89bfJbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequence.map(split_input_target)"
      ],
      "metadata": {
        "id": "mBeh3efk-qsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 2048\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
      ],
      "metadata": {
        "id": "xM8kEaWA_cI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model using LSTM (Long Short Term Memory)"
      ],
      "metadata": {
        "id": "wmXak8-kAo6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim ,rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\n",
        "      tf.keras.layers.LSTM(\n",
        "          rnn_units, return_sequences = True, stateful = True, recurrent_initializer = 'glorot_uniform'\n",
        "      ),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW6thLPdAmF0",
        "outputId": "aee60eaa-08b4-4b00-8d24-e91a24e5372d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (32, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (32, None, 2048)          18882560  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (32, None, 65)            133185    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19032385 (72.60 MB)\n",
            "Trainable params: 19032385 (72.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function\n",
        "Desc :"
      ],
      "metadata": {
        "id": "2u48bW5JEEUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICicwG_mCQG5",
        "outputId": "48b6915f-3474-4e95-aa27-cb0f10dc69d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 200, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of example_batch_predictions\",len(example_batch_predictions), \"\\n\")\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQvyb9q7E2x5",
        "outputId": "78285117-cdfc-4e5d-cede-a897a4411416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of example_batch_predictions 32 \n",
            "\n",
            "tf.Tensor(\n",
            "[[[ 2.7246634e-03  1.1690214e-03 -1.5965368e-03 ... -2.0077222e-03\n",
            "    3.6962546e-04  3.3993216e-04]\n",
            "  [ 1.5784656e-03 -2.2637506e-03 -1.5222246e-04 ... -1.4191504e-03\n",
            "   -1.2149583e-03 -3.1869390e-04]\n",
            "  [ 2.8345603e-03 -5.2033388e-03 -2.3174698e-03 ... -6.4780549e-03\n",
            "   -5.3607593e-03  6.2577655e-03]\n",
            "  ...\n",
            "  [ 1.4481845e-03  4.8759533e-03 -7.3092151e-03 ...  1.9128630e-03\n",
            "   -2.6438916e-03  4.8190202e-03]\n",
            "  [ 2.8555584e-03 -1.5968952e-03 -8.7337010e-03 ... -4.3838006e-03\n",
            "   -7.0376880e-03  1.0341837e-02]\n",
            "  [ 3.5035997e-03 -2.2408848e-03 -6.9076419e-03 ... -6.8659405e-03\n",
            "   -6.3328124e-03  1.0142503e-02]]\n",
            "\n",
            " [[ 1.7843676e-03 -7.7717390e-04  8.3439099e-03 ... -6.2653527e-04\n",
            "   -3.1500403e-03  4.5896473e-04]\n",
            "  [-8.4852567e-05  1.6541654e-03  5.0980095e-03 ... -5.6973461e-04\n",
            "   -4.9515618e-03 -8.6011225e-04]\n",
            "  [-6.3149852e-04 -5.5379770e-04  4.4541005e-03 ... -4.1442085e-04\n",
            "   -4.8808600e-03 -7.0883322e-04]\n",
            "  ...\n",
            "  [ 6.7332471e-03  1.3161695e-04 -2.1964428e-03 ... -2.7021354e-03\n",
            "   -7.7049469e-04  3.3539510e-03]\n",
            "  [ 7.6060588e-03 -8.1335683e-04 -1.8448333e-03 ... -6.5599522e-04\n",
            "   -1.3655529e-03  6.0531623e-03]\n",
            "  [ 7.1838917e-03 -1.3677205e-04 -1.2849269e-03 ... -3.9253919e-03\n",
            "   -8.1024715e-04  6.6320756e-03]]\n",
            "\n",
            " [[ 1.6895519e-03  7.4388192e-04 -1.4488224e-03 ...  7.0217904e-04\n",
            "   -7.3595694e-04 -2.9458685e-03]\n",
            "  [ 7.3130592e-04 -1.0440394e-03 -1.1504947e-03 ...  4.1786917e-03\n",
            "    7.1731592e-03  2.8852625e-03]\n",
            "  [ 1.9104603e-03 -5.0971527e-03 -4.5160097e-03 ... -2.4979792e-03\n",
            "    1.8979928e-03  7.0747966e-03]\n",
            "  ...\n",
            "  [-1.2204158e-03  1.7201273e-04 -7.9497099e-03 ...  2.9554646e-03\n",
            "    1.1289914e-03  8.7030623e-03]\n",
            "  [-1.2126688e-03  2.6426674e-03 -7.4368874e-03 ...  7.6051615e-03\n",
            "    4.8576482e-03  1.5773403e-03]\n",
            "  [-2.8885687e-03  3.6223314e-03 -5.1389355e-03 ... -6.4650521e-05\n",
            "    1.7472059e-03  3.5928588e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.4251828e-03 -6.4303924e-04  1.6825551e-03 ... -8.0797146e-04\n",
            "   -1.9641854e-03 -4.1423313e-04]\n",
            "  [ 4.0407581e-03  3.0351384e-03  1.3480507e-03 ... -1.0936294e-04\n",
            "   -2.7455058e-04 -3.3701654e-03]\n",
            "  [ 7.5329235e-04  4.4692922e-03 -1.3496128e-03 ...  1.1271011e-04\n",
            "   -2.8850096e-03 -3.5179078e-03]\n",
            "  ...\n",
            "  [-2.9249839e-04  1.4765833e-03 -3.8489830e-03 ...  3.5770787e-03\n",
            "    5.0722146e-03 -6.3098245e-03]\n",
            "  [ 1.8709595e-03 -1.1260095e-03 -3.3843149e-03 ...  2.2436616e-03\n",
            "    2.6039062e-03 -2.2991439e-03]\n",
            "  [ 4.1320650e-03 -7.5175893e-05 -4.6277628e-03 ... -1.3711916e-03\n",
            "    2.7862876e-03 -1.9114278e-03]]\n",
            "\n",
            " [[ 1.7843673e-03 -7.7717408e-04  8.3439108e-03 ... -6.2653539e-04\n",
            "   -3.1500412e-03  4.5896473e-04]\n",
            "  [ 2.8642807e-03  7.5610005e-04  4.8319171e-03 ...  1.3659766e-04\n",
            "   -2.9198048e-03 -2.1187738e-03]\n",
            "  [-2.8045708e-03  2.2265816e-03 -1.2547416e-03 ...  2.7709864e-03\n",
            "    1.1834593e-03 -1.8486208e-03]\n",
            "  ...\n",
            "  [ 5.4574888e-03 -1.9293636e-03 -4.5232335e-03 ...  9.7990793e-04\n",
            "    5.5284444e-03  7.2549675e-03]\n",
            "  [ 6.1085974e-03 -5.9895157e-03 -6.8669082e-03 ... -4.4500777e-03\n",
            "    3.2836589e-04  1.1949863e-02]\n",
            "  [ 7.5800465e-03 -5.9013409e-03 -5.7518585e-03 ... -2.1267671e-03\n",
            "   -6.2193203e-04  1.1787878e-02]]\n",
            "\n",
            " [[ 1.1862760e-03 -2.5400962e-04  2.3426177e-04 ... -3.5278967e-03\n",
            "   -6.3114881e-04  1.4961520e-03]\n",
            "  [ 3.0099896e-03 -1.3520360e-03  3.8945617e-04 ... -1.4531424e-03\n",
            "   -1.5416445e-03  2.8675166e-03]\n",
            "  [ 6.4412877e-04  1.4609606e-03  1.0917186e-03 ... -5.7532820e-03\n",
            "   -3.0122153e-03  2.7991571e-03]\n",
            "  ...\n",
            "  [ 2.5493633e-03 -1.4519161e-03 -4.1140472e-03 ... -1.3136500e-03\n",
            "   -1.6936006e-03  7.0441980e-03]\n",
            "  [ 2.7036029e-03 -2.6212139e-03 -3.6330901e-03 ... -1.3394852e-03\n",
            "   -3.2944521e-03  5.4311464e-03]\n",
            "  [ 1.7352878e-03 -2.4230278e-04 -3.9122161e-03 ...  5.5996319e-03\n",
            "    1.8592475e-03  3.0174095e-04]]], shape=(32, 200, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a custom Loss function to perform out optimization"
      ],
      "metadata": {
        "id": "HFsnwv8mR3W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "dUoBAf4_FHP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65bff01-7150-4092-c971-cbc729fb0b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "tf.Tensor(\n",
            "[[ 0.00272466  0.00116902 -0.00159654 ... -0.00200772  0.00036963\n",
            "   0.00033993]\n",
            " [ 0.00157847 -0.00226375 -0.00015222 ... -0.00141915 -0.00121496\n",
            "  -0.00031869]\n",
            " [ 0.00283456 -0.00520334 -0.00231747 ... -0.00647805 -0.00536076\n",
            "   0.00625777]\n",
            " ...\n",
            " [ 0.00144818  0.00487595 -0.00730922 ...  0.00191286 -0.00264389\n",
            "   0.00481902]\n",
            " [ 0.00285556 -0.0015969  -0.0087337  ... -0.0043838  -0.00703769\n",
            "   0.01034184]\n",
            " [ 0.0035036  -0.00224088 -0.00690764 ... -0.00686594 -0.00633281\n",
            "   0.0101425 ]], shape=(200, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mELmzHLHTzlb",
        "outputId": "ca7dd3b4-2ffe-452e-ffbf-85af9cf00724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 2.7246634e-03  1.1690214e-03 -1.5965368e-03 -1.7640952e-03\n",
            " -5.9527368e-04  1.1023791e-03 -1.4383618e-03  2.0313880e-03\n",
            " -2.8294602e-03  3.1035452e-03 -4.1371291e-03  1.7659286e-03\n",
            " -5.9656601e-04 -2.2176290e-03  3.7069845e-03 -7.8749261e-04\n",
            "  8.6131843e-04 -4.2455550e-04 -1.4757439e-03 -5.8861001e-04\n",
            " -3.9184517e-03  3.1359824e-03 -1.6766804e-03 -6.5812643e-04\n",
            "  7.0843118e-05 -1.3016215e-04  1.1619422e-04  6.7235163e-04\n",
            " -1.0893401e-03  1.7666025e-06  5.0595973e-04  3.2460345e-03\n",
            "  3.1148572e-04 -8.2633906e-04 -3.3998252e-03  3.3215834e-03\n",
            "  2.2598309e-03 -1.7614985e-03  4.4242060e-04  3.3725540e-03\n",
            "  1.4756802e-03  1.6007364e-03  2.2256949e-03 -4.1714702e-03\n",
            " -5.6756556e-04 -1.8880441e-03  1.1056193e-04  1.4885502e-03\n",
            "  8.1109419e-04 -1.5448087e-03  2.3874517e-03  2.6266424e-03\n",
            "  6.2636170e-03 -1.4396058e-03 -3.4890294e-03 -3.0538521e-03\n",
            "  3.9501791e-03 -5.2246096e-04  4.5357074e-04  1.6164255e-03\n",
            " -3.7670250e-03 -3.8552284e-04 -2.0077222e-03  3.6962546e-04\n",
            "  3.3993216e-04], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indeces = tf.random.categorical(pred, num_samples = 1)\n",
        "sampled_indeces.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZLSkqK9ULnp",
        "outputId": "1b602fdc-ae49-4b22-a15e-3cc7de043894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([200, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indeces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQNWIANVWheO",
        "outputId": "89b1d633-70c4-4f29-9526-ba6e88a48b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(200, 1), dtype=int64, numpy=\n",
              "array([[12],\n",
              "       [18],\n",
              "       [50],\n",
              "       [28],\n",
              "       [20],\n",
              "       [62],\n",
              "       [23],\n",
              "       [50],\n",
              "       [16],\n",
              "       [45],\n",
              "       [59],\n",
              "       [37],\n",
              "       [25],\n",
              "       [40],\n",
              "       [ 0],\n",
              "       [58],\n",
              "       [33],\n",
              "       [ 8],\n",
              "       [ 6],\n",
              "       [51],\n",
              "       [40],\n",
              "       [57],\n",
              "       [25],\n",
              "       [10],\n",
              "       [52],\n",
              "       [ 5],\n",
              "       [47],\n",
              "       [18],\n",
              "       [26],\n",
              "       [26],\n",
              "       [25],\n",
              "       [62],\n",
              "       [39],\n",
              "       [51],\n",
              "       [42],\n",
              "       [ 5],\n",
              "       [31],\n",
              "       [21],\n",
              "       [ 8],\n",
              "       [ 0],\n",
              "       [49],\n",
              "       [60],\n",
              "       [52],\n",
              "       [40],\n",
              "       [62],\n",
              "       [38],\n",
              "       [40],\n",
              "       [ 7],\n",
              "       [ 8],\n",
              "       [ 1],\n",
              "       [21],\n",
              "       [25],\n",
              "       [25],\n",
              "       [49],\n",
              "       [39],\n",
              "       [29],\n",
              "       [59],\n",
              "       [60],\n",
              "       [42],\n",
              "       [44],\n",
              "       [ 7],\n",
              "       [51],\n",
              "       [61],\n",
              "       [33],\n",
              "       [30],\n",
              "       [57],\n",
              "       [25],\n",
              "       [31],\n",
              "       [43],\n",
              "       [31],\n",
              "       [46],\n",
              "       [ 9],\n",
              "       [34],\n",
              "       [47],\n",
              "       [46],\n",
              "       [20],\n",
              "       [41],\n",
              "       [31],\n",
              "       [39],\n",
              "       [29],\n",
              "       [40],\n",
              "       [ 1],\n",
              "       [35],\n",
              "       [57],\n",
              "       [36],\n",
              "       [49],\n",
              "       [ 5],\n",
              "       [ 2],\n",
              "       [56],\n",
              "       [ 2],\n",
              "       [27],\n",
              "       [18],\n",
              "       [33],\n",
              "       [43],\n",
              "       [ 7],\n",
              "       [35],\n",
              "       [ 7],\n",
              "       [60],\n",
              "       [46],\n",
              "       [17],\n",
              "       [58],\n",
              "       [52],\n",
              "       [12],\n",
              "       [37],\n",
              "       [60],\n",
              "       [ 5],\n",
              "       [47],\n",
              "       [58],\n",
              "       [63],\n",
              "       [12],\n",
              "       [48],\n",
              "       [46],\n",
              "       [16],\n",
              "       [34],\n",
              "       [42],\n",
              "       [ 8],\n",
              "       [41],\n",
              "       [39],\n",
              "       [34],\n",
              "       [ 4],\n",
              "       [50],\n",
              "       [64],\n",
              "       [16],\n",
              "       [46],\n",
              "       [ 3],\n",
              "       [26],\n",
              "       [50],\n",
              "       [48],\n",
              "       [56],\n",
              "       [37],\n",
              "       [62],\n",
              "       [ 8],\n",
              "       [42],\n",
              "       [ 4],\n",
              "       [28],\n",
              "       [41],\n",
              "       [42],\n",
              "       [47],\n",
              "       [35],\n",
              "       [15],\n",
              "       [18],\n",
              "       [53],\n",
              "       [12],\n",
              "       [50],\n",
              "       [16],\n",
              "       [37],\n",
              "       [ 3],\n",
              "       [17],\n",
              "       [13],\n",
              "       [60],\n",
              "       [39],\n",
              "       [56],\n",
              "       [12],\n",
              "       [26],\n",
              "       [ 7],\n",
              "       [63],\n",
              "       [13],\n",
              "       [10],\n",
              "       [63],\n",
              "       [ 1],\n",
              "       [60],\n",
              "       [25],\n",
              "       [43],\n",
              "       [50],\n",
              "       [20],\n",
              "       [32],\n",
              "       [47],\n",
              "       [33],\n",
              "       [ 2],\n",
              "       [62],\n",
              "       [30],\n",
              "       [37],\n",
              "       [30],\n",
              "       [28],\n",
              "       [55],\n",
              "       [ 8],\n",
              "       [ 5],\n",
              "       [64],\n",
              "       [34],\n",
              "       [43],\n",
              "       [ 8],\n",
              "       [27],\n",
              "       [23],\n",
              "       [41],\n",
              "       [ 9],\n",
              "       [ 8],\n",
              "       [50],\n",
              "       [57],\n",
              "       [28],\n",
              "       [57],\n",
              "       [51],\n",
              "       [41],\n",
              "       [47],\n",
              "       [30],\n",
              "       [17],\n",
              "       [15],\n",
              "       [39],\n",
              "       [53],\n",
              "       [10],\n",
              "       [ 5]])>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indeces = np.reshape(sampled_indeces, (1,-1))[0]\n",
        "sampled_indeces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I0ZOv-GU67Y",
        "outputId": "23d937db-921d-419e-e51f-389930bc53ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12, 18, 50, 28, 20, 62, 23, 50, 16, 45, 59, 37, 25, 40,  0, 58, 33,\n",
              "        8,  6, 51, 40, 57, 25, 10, 52,  5, 47, 18, 26, 26, 25, 62, 39, 51,\n",
              "       42,  5, 31, 21,  8,  0, 49, 60, 52, 40, 62, 38, 40,  7,  8,  1, 21,\n",
              "       25, 25, 49, 39, 29, 59, 60, 42, 44,  7, 51, 61, 33, 30, 57, 25, 31,\n",
              "       43, 31, 46,  9, 34, 47, 46, 20, 41, 31, 39, 29, 40,  1, 35, 57, 36,\n",
              "       49,  5,  2, 56,  2, 27, 18, 33, 43,  7, 35,  7, 60, 46, 17, 58, 52,\n",
              "       12, 37, 60,  5, 47, 58, 63, 12, 48, 46, 16, 34, 42,  8, 41, 39, 34,\n",
              "        4, 50, 64, 16, 46,  3, 26, 50, 48, 56, 37, 62,  8, 42,  4, 28, 41,\n",
              "       42, 47, 35, 15, 18, 53, 12, 50, 16, 37,  3, 17, 13, 60, 39, 56, 12,\n",
              "       26,  7, 63, 13, 10, 63,  1, 60, 25, 43, 50, 20, 32, 47, 33,  2, 62,\n",
              "       30, 37, 30, 28, 55,  8,  5, 64, 34, 43,  8, 27, 23, 41,  9,  8, 50,\n",
              "       57, 28, 57, 51, 41, 47, 30, 17, 15, 39, 53, 10,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_chars = decoder(sampled_indeces)\n",
        "predicted_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "sG5tHy-sg7wO",
        "outputId": "862dcace-c188-47ba-d284-bf714620aeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"?FlPHxKlDguYMb\\ntU.,mbsM:n'iFNNMxamd'SI.\\nkvnbxZb-. IMMkaQuvdf-mwURsMSeSh3VihHcSaQb WsXk'!r!OFUe-W-vhEtn?Yv'ity?jhDVd.caV&lzDh$NljrYx.d&PcdiWCFo?lDY$EAvar?N-yA:y vMelHTiU!xRYRPq.'zVe.OKc3.lsPsmciRECao:'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(labels, logits):\n",
        "  loss_fun =  tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "  return loss_fun(labels, logits)\n"
      ],
      "metadata": {
        "id": "9W6AfUbmhGDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Compilation"
      ],
      "metadata": {
        "id": "_VK81IjnhUc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = custom_loss)"
      ],
      "metadata": {
        "id": "BU73YcMPhS9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dr = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dr, 'ckpt_{epoch}')\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_prefix,\n",
        "    save_weights_only = True\n",
        ")"
      ],
      "metadata": {
        "id": "9Z87dappheql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data, epochs = 4 ,callbacks = [checkpoint_callback])"
      ],
      "metadata": {
        "id": "GWbamrFXiRmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size = 1)"
      ],
      "metadata": {
        "id": "RoJ1DLCuixfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dr))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "Z8biyk6cu5p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generated = 500 # Number of characters will get generate\n",
        "\n",
        "  input_eval = encoder(start_string)\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  result_arr = []\n",
        "\n",
        "  # tempearture varies from 0 to 1 and it decides the randomness or predictivity of our result.\n",
        "  # lower the temperature results more predictable results.\n",
        "\n",
        "  temperature = 1.0\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generated):\n",
        "    predictions = model(input_eval)\n",
        "\n",
        "    # remove the batch dimension\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # using a categorical distribution to predict the character returned by the model\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1,0].numpy()\n",
        "\n",
        "    # we pass the predicted character as the next input to the model\n",
        "    # along with the previous hidden state\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(decoder(predicted_id))\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "ztZ3kesevFaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "metadata": {
        "id": "unTasieW3AoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r7zSVkTn3PHh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}